{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import Metrics\n",
    "# from STTN import *\n",
    "from Param import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from folder workPEMSD7M\n",
    "\n",
    "# MODEL CODE\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sep 28 10:28:06 2020\n",
    "\n",
    "@author: wb\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from GCN_models import GCN\n",
    "# from One_hot_encoder import One_hot_encoder\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigs\n",
    "import pandas as pd\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "# def cheb_polynomial(L_tilde, K):\n",
    "#     '''\n",
    "#     compute a list of chebyshev polynomials from T_0 to T_{K-1}\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     L_tilde: scaled Laplacian, np.ndarray, shape (N, N)\n",
    "\n",
    "#     K: the maximum order of chebyshev polynomials\n",
    "\n",
    "#     Returns\n",
    "#     ----------\n",
    "#     cheb_polynomials: list(np.ndarray), length: K, from T_0 to T_{K-1}\n",
    "\n",
    "#     '''\n",
    "\n",
    "#     N = L_tilde.shape[0]\n",
    "\n",
    "#     cheb_polynomials = [np.identity(N), L_tilde.copy()]\n",
    "\n",
    "#     for i in range(2, K):\n",
    "#         cheb_polynomials.append(2 * L_tilde * cheb_polynomials[i - 1] - cheb_polynomials[i - 2])\n",
    "\n",
    "#     return cheb_polynomials\n",
    "\n",
    "# def scaled_Laplacian(W):\n",
    "#     '''\n",
    "#     compute \\tilde{L}\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     W: np.ndarray, shape is (N, N), N is the num of vertices\n",
    "\n",
    "#     Returns\n",
    "#     ----------\n",
    "#     scaled_Laplacian: np.ndarray, shape (N, N)\n",
    "\n",
    "#     '''\n",
    "\n",
    "#     assert W.shape[0] == W.shape[1]\n",
    "\n",
    "#     D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "#     L = D - W\n",
    "\n",
    "#     lambda_max = eigs(L, k=1, which='LR')[0].real\n",
    "\n",
    "#     return (2 * L) / lambda_max - np.identity(W.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class GraphConvolution(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, in_features, out_features, bias=True):\n",
    "#         super(GraphConvolution, self).__init__()\n",
    "#         self.in_features = in_features\n",
    "#         self.out_features = out_features\n",
    "#         self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "#         if bias:\n",
    "#             self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "#         else:\n",
    "#             self.register_parameter('bias', None)\n",
    "#         self.reset_parameters()\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "#         self.weight.data.uniform_(-stdv, stdv)\n",
    "#         if self.bias is not None:\n",
    "#             self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "#     def forward(self, x, adj):\n",
    "#         support = torch.mm(x, self.weight)\n",
    "#         output = torch.spmm(adj, support)\n",
    "#         if self.bias is not None:\n",
    "#             return output + self.bias\n",
    "#         else:\n",
    "#             return output\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return self.__class__.__name__ + ' (' \\\n",
    "#                + str(self.in_features) + ' -> ' \\\n",
    "#                + str(self.out_features) + ')'\n",
    "\n",
    "    \n",
    "# class cheb_conv(nn.Module):\n",
    "#     '''\n",
    "#     K-order chebyshev graph convolution\n",
    "#     '''\n",
    "#     def __init__(self, in_features, out_features, adj, K, bias=True):\n",
    "# #     def __init__(self, nfeat, nhid, nclass, dropout, K):\n",
    "# #     def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n",
    "#         '''\n",
    "#         :param K: int\n",
    "#         :param in_channles: int, num of channels in the input sequence\n",
    "#         :param out_channels: int, num of channels in the output sequence\n",
    "#         '''\n",
    "#         super(cheb_conv, self).__init__()\n",
    "#         self.DEVICE = DEVICE\n",
    "#         self.K = K\n",
    "#         adj = np.array(adj.cpu())\n",
    "#         L_tilde = scaled_Laplacian(adj)\n",
    "#         self.cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(self.DEVICE) for i in cheb_polynomial(L_tilde, K)]\n",
    "        \n",
    "        \n",
    "#         self.in_channels = in_features\n",
    "#         self.out_channels = out_features\n",
    "        \n",
    "#         self.Theta = nn.ParameterList([nn.Parameter(torch.randn(self.in_channels, self.out_channels).to(self.DEVICE)) for _ in range(K)])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         '''\n",
    "#         Chebyshev graph convolution operation\n",
    "#         :param x: (B, N, C] --> (batch_size, N, F_in, T)\n",
    "#         :return: (batch_size, N, F_out, T)\n",
    "#         '''\n",
    "# #         x = x.permute(0, 1, 3, 2)\n",
    "#         batch_size, num_of_vertices, in_channels = x.shape\n",
    "\n",
    "           \n",
    "\n",
    "#         graph_signal = x\n",
    "\n",
    "#         output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n",
    "\n",
    "#         for k in range(self.K):\n",
    "\n",
    "#             T_k = self.cheb_polynomials[k]  # (N,N)\n",
    "\n",
    "#             theta_k = self.Theta[k]  # (in_channel, out_channel)\n",
    "\n",
    "#             rhs = graph_signal.permute(0, 2, 1).matmul(T_k).permute(0, 2, 1) # （b, F_in, N) * (N, N) --> (b, F_in, N) --> (b, N, F_in)\n",
    "\n",
    "#             output = output + rhs.matmul(theta_k) # (b, N, F_in) * (F_in, F_out) --> (b, N, F_out) \n",
    "\n",
    "\n",
    "        \n",
    "#         result = F.relu(output)\n",
    "\n",
    "#         return result\n",
    "\n",
    "class One_hot_encoder(nn.Module):\n",
    "    def __init__(self, embed_size, time_num = 288):\n",
    "        super(One_hot_encoder, self).__init__()\n",
    "        \n",
    "        self.time_num = time_num\n",
    "        self.I = nn.Parameter(torch.eye(time_num, time_num, requires_grad=True))\n",
    "        self.onehot_Linear = nn.Linear(time_num, embed_size)     # 线性层改变one hot编码维度\n",
    "\n",
    "    def forward(self, i, N = 25, T = 12):\n",
    "    \n",
    "        if i%self.time_num+T > self.time_num :\n",
    "            o1 = self.I[i%self.time_num : , : ]\n",
    "            o2 = self.I[0 : (i+T)%self.time_num, : ]\n",
    "            onehot = torch.cat((o1, o2), 0)\n",
    "        else:        \n",
    "            onehot = self.I[i%self.time_num: i%self.time_num+T, : ]\n",
    "        \n",
    "        #onehot = onehot.repeat(N, 1, 1)   \n",
    "        onehot = onehot.expand(N, T, self.time_num)\n",
    "        onehot = self.onehot_Linear(onehot)\n",
    "        return onehot\n",
    "    \n",
    "\n",
    "# class GCN(nn.Module):\n",
    "#     def __init__(self, nfeat, nhid, nclass, adj, cheb_K, dropout):\n",
    "#         super(GCN, self).__init__()\n",
    "\n",
    "#         self.gc1 = cheb_conv(nfeat, nhid, adj, cheb_K)\n",
    "#         self.gc2 = cheb_conv(nhid, nclass, adj, cheb_K)\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#     def forward(self, x, adj):\n",
    "#         x = F.relu(self.gc1(x))\n",
    "#         x = F.dropout(x, self.dropout, training=self.training)\n",
    "#         x = self.gc2(x)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        '''\n",
    "        Q: [batch_size, n_heads, T(Spatial) or N(Temporal), N(Spatial) or T(Temporal), d_k]\n",
    "        K: [batch_size, n_heads, T(Spatial) or N(Temporal), N(Spatial) or T(Temporal), d_k]\n",
    "        V: [batch_size, n_heads, T(Spatial) or N(Temporal), N(Spatial) or T(Temporal), d_k]\n",
    "        attn_mask: [batch_size, n_heads, seq_len, seq_len] 可能没有\n",
    "        '''\n",
    "        B, n_heads, len1, len2, d_k = Q.shape \n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) \n",
    "        # scores : [batch_size, n_heads, T(Spatial) or N(Temporal), N(Spatial) or T(Temporal), N(Spatial) or T(Temporal)]\n",
    "        # scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n",
    "        \n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V) # [batch_size, n_heads, T(Spatial) or N(Temporal), N(Spatial) or T(Temporal), d_k]]\n",
    "        return context\n",
    "\n",
    "\n",
    "\n",
    "class SMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SMultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "            \n",
    "        # 用Linear来做投影矩阵    \n",
    "        # 但这里如果是多头的话，是不是需要声明多个矩阵？？？\n",
    "\n",
    "        self.W_V = nn.Linear(self.embed_size, self.head_dim * self.heads, bias=False)\n",
    "        self.W_K = nn.Linear(self.embed_size, self.head_dim * self.heads, bias=False)\n",
    "        self.W_Q = nn.Linear(self.embed_size, self.head_dim * self.heads, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "    def forward(self, input_Q, input_K, input_V):\n",
    "        '''\n",
    "        input_Q: [batch_size, N, T, C]\n",
    "        input_K: [batch_size, N, T, C]\n",
    "        input_V: [batch_size, N, T, C]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        '''\n",
    "        B, N, T, C = input_Q.shape\n",
    "#         print('input Q shape: ',input_Q.shape)\n",
    "        # [B, N, T, C] --> [B, N, T, h * d_k] --> [B, N, T, h, d_k] --> [B, h, T, N, d_k]\n",
    "        Q = self.W_Q(input_Q).view(B, N, T, self.heads, self.head_dim).transpose(1, 3)  # Q: [B, h, T, N, d_k]\n",
    "        K = self.W_K(input_K).view(B, N, T, self.heads, self.head_dim).transpose(1, 3)  # K: [B, h, T, N, d_k]\n",
    "        V = self.W_V(input_V).view(B, N, T, self.heads, self.head_dim).transpose(1, 3)  # V: [B, h, T, N, d_k]\n",
    "\n",
    "        # attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n",
    "\n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context = ScaledDotProductAttention()(Q, K, V) # [B, h, T, N, d_k]\n",
    "        context = context.permute(0, 3, 2, 1, 4) #[B, N, T, h, d_k]\n",
    "        context = context.reshape(B, N, T, self.heads * self.head_dim) # [B, N, T, C]\n",
    "        # context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) # context: [batch_size, len_q, n_heads * d_v]\n",
    "        output = self.fc_out(context) # [batch_size, len_q, d_model]\n",
    "        return output\n",
    "\n",
    "\n",
    "class TMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(TMultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "            \n",
    "        # 用Linear来做投影矩阵    \n",
    "        # 但这里如果是多头的话，是不是需要声明多个矩阵？？？\n",
    "\n",
    "        self.W_V = nn.Linear(self.embed_size, self.head_dim * self.heads, bias=False)\n",
    "        self.W_K = nn.Linear(self.embed_size, self.head_dim * self.heads, bias=False)\n",
    "        self.W_Q = nn.Linear(self.embed_size, self.head_dim * self.heads, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "    def forward(self, input_Q, input_K, input_V):\n",
    "        '''\n",
    "        input_Q: [batch_size, N, T, C]\n",
    "        input_K: [batch_size, N, T, C]\n",
    "        input_V: [batch_size, N, T, C]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        '''\n",
    "        B, N, T, C = input_Q.shape\n",
    "        # [B, N, T, C] --> [B, N, T, h * d_k] --> [B, N, T, h, d_k] --> [B, h, N, T, d_k]\n",
    "        Q = self.W_Q(input_Q).view(B, N, T, self.heads, self.head_dim).permute(0, 3, 1, 2, 4) # Q: [B, h, N, T, d_k]\n",
    "        K = self.W_K(input_K).view(B, N, T, self.heads, self.head_dim).permute(0, 3, 1, 2, 4)  # K: [B, h, N, T, d_k]\n",
    "        V = self.W_V(input_V).view(B, N, T, self.heads, self.head_dim).permute(0, 3, 1, 2, 4)  # V: [B, h, N, T, d_k]\n",
    "\n",
    "        # attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n",
    "\n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context = ScaledDotProductAttention()(Q, K, V) #[B, h, N, T, d_k]\n",
    "        context = context.permute(0, 2, 3, 1, 4) #[B, N, T, h, d_k]\n",
    "        context = context.reshape(B, N, T, self.heads * self.head_dim) # [B, N, T, C]\n",
    "        # context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) # context: [batch_size, len_q, n_heads * d_v]\n",
    "        output = self.fc_out(context) # [batch_size, len_q, d_model]\n",
    "        return output \n",
    "\n",
    "\n",
    "\n",
    "class STransformer(nn.Module):\n",
    "    def __init__(self, embed_size, heads, adj, cheb_K, dropout, forward_expansion):\n",
    "        super(STransformer, self).__init__()\n",
    "        # Spatial Embedding\n",
    "        self.adj = adj\n",
    "        \n",
    "#         print(adj)\n",
    "#         print(adj.shape)\n",
    "        \n",
    "        self.D_S = adj.to(DEVICE) # 为什么是邻接矩阵\n",
    "        self.embed_liner = nn.Linear(adj.shape[0], embed_size)\n",
    "        \n",
    "        self.attention = SMultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "        \n",
    "        # 调用GCN\n",
    "#         删掉GCN\n",
    "#         self.gcn = GCN(embed_size, embed_size*2, embed_size, adj, cheb_K, dropout)  \n",
    "        self.norm_adj = nn.InstanceNorm2d(1)    # 对邻接矩阵归一化\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fs = nn.Linear(embed_size, embed_size)\n",
    "        self.fg = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, value, key, query):\n",
    "        # value, key, query: [N, T, C]  [B, N, T, C]        \n",
    "        # Spatial Embedding 部分 \n",
    "#         N, T, C = query.shape\n",
    "#         D_S = self.embed_liner(self.D_S) # [N, C]\n",
    "#         D_S = D_S.expand(T, N, C) #[T, N, C]相当于在第一维复制了T份\n",
    "#         D_S = D_S.permute(1, 0, 2) #[N, T, C]\n",
    "        B, N, T, C = query.shape\n",
    "        D_S = self.embed_liner(self.D_S) # [N, C] \n",
    "        # \n",
    "        D_S = D_S.expand(B, T, N, C) #[B, T, N, C]相当于在第2维复制了T份, 第一维复制B份\n",
    "        D_S = D_S.permute(0, 2, 1, 3) #[B, N, T, C]\n",
    "        \n",
    "        \n",
    "#         # GCN 部分\n",
    "\n",
    "\n",
    "#         X_G = torch.Tensor(B, N,  0, C).to(DEVICE)\n",
    "#         self.adj = self.adj.unsqueeze(0).unsqueeze(0)\n",
    "#         self.adj = self.norm_adj(self.adj)\n",
    "#         self.adj = self.adj.squeeze(0).squeeze(0)\n",
    "        \n",
    "#         for t in range(query.shape[2]):\n",
    "#             o = self.gcn(query[ : ,:,  t,  : ],  self.adj) # [B, N, C]\n",
    "#             o = o.unsqueeze(2)              # shape [N, 1, C] [B, N, 1, C]\n",
    "# #             print(o.shape)\n",
    "#             X_G = torch.cat((X_G, o), dim=2)\n",
    "#          # 最后X_G [B, N, T, C]   \n",
    "        \n",
    "#         print('After GCN:')\n",
    "#         print(X_G)\n",
    "        # Spatial Transformer 部分\n",
    "        query = query + D_S\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        attention = self.attention(query, query, query) #(B, N, T, C)\n",
    "        # Add skip connection, run through normalization and finally dropout\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        U_S = self.dropout(self.norm2(forward + x))\n",
    "\n",
    "        \n",
    "        # 融合 STransformer and GCN  \n",
    "#         g = torch.sigmoid(self.fs(U_S) +  self.fg(X_G))      # (7)\n",
    "#         out = g*U_S + (1-g)*X_G                                # (8)\n",
    "        \n",
    "        out = U_S\n",
    "        return out #(B, N, T, C)    \n",
    "\n",
    "\n",
    "class TTransformer(nn.Module):\n",
    "    def __init__(self, embed_size, heads, time_num, dropout, forward_expansion):\n",
    "        super(TTransformer, self).__init__()\n",
    "        \n",
    "        # Temporal embedding One hot\n",
    "        self.time_num = time_num\n",
    "#         self.one_hot = One_hot_encoder(embed_size, time_num)          # temporal embedding选用one-hot方式 或者\n",
    "        self.temporal_embedding = nn.Embedding(time_num, embed_size)  # temporal embedding选用nn.Embedding\n",
    "\n",
    "\n",
    "        \n",
    "        self.attention = TMultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, t):\n",
    "        B, N, T, C = query.shape\n",
    "        \n",
    "#         D_T = self.one_hot(t, N, T)                          # temporal embedding选用one-hot方式 或者\n",
    "        D_T = self.temporal_embedding(torch.arange(0, T).to(DEVICE))    # temporal embedding选用nn.Embedding \n",
    "    # POSITON ENCODING\n",
    "        D_T = D_T.expand(B, N, T, C)\n",
    "\n",
    "\n",
    "        # temporal embedding加到query。 原论文采用concatenated\n",
    "        query = query + D_T  \n",
    "        \n",
    "        attention = self.attention(query, query, query) # SELF-ATTENTION 的QKV都是一样，因为不是nlp\n",
    "\n",
    "        # Add skip connection, run through normalization and finally dropout\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### STBlock\n",
    "\n",
    "class STTransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, adj, time_num, cheb_K, dropout, forward_expansion):\n",
    "        super(STTransformerBlock, self).__init__()\n",
    "        self.STransformer = STransformer(embed_size, heads, adj, cheb_K, dropout, forward_expansion)\n",
    "        self.TTransformer = TTransformer(embed_size, heads, time_num, dropout, forward_expansion)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, value, key, query, t):\n",
    "    # value,  key, query: [N, T, C] [B, N, T, C]\n",
    "        # Add skip connection,run through normalization and finally dropout\n",
    "        x1 = self.norm1(self.STransformer(value, key, query) + query) #(B, N, T, C)\n",
    "        x2 = self.dropout( self.norm2(self.TTransformer(x1, x1, x1, t) + x1) ) \n",
    "        return x2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Encoder\n",
    "class Encoder(nn.Module):\n",
    "    # 堆叠多层 ST-Transformer Block\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        adj,\n",
    "        time_num,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        cheb_K,\n",
    "        dropout,\n",
    "    ):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                STTransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    adj,\n",
    "                    time_num,\n",
    "                    cheb_K,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "    # x: [N, T, C]  [B, N, T, C]\n",
    "        out = self.dropout(x)        \n",
    "        # In the Encoder the query, key, value are all the same.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, t)\n",
    "        return out     \n",
    "    \n",
    "\n",
    "\n",
    "### Transformer   \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        adj,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        time_num,\n",
    "        forward_expansion, ##？\n",
    "        cheb_K,\n",
    "        dropout,\n",
    "        \n",
    "        device=DEVICE\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            adj,\n",
    "            time_num,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            cheb_K,\n",
    "            dropout\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, t): \n",
    "        ## scr: [N, T, C]   [B, N, T, C]\n",
    "        enc_src = self.encoder(src, t) \n",
    "        return enc_src # [B, N, T, C]\n",
    "\n",
    "\n",
    "### ST Transformer: Total Model\n",
    "\n",
    "class STTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        adj,\n",
    "        in_channels, \n",
    "        embed_size, \n",
    "        time_num,\n",
    "        num_layers,\n",
    "        T_dim,\n",
    "        output_T_dim,  \n",
    "        heads,    \n",
    "        cheb_K,\n",
    "        forward_expansion,\n",
    "        dropout = 0\n",
    "    ):        \n",
    "        super(STTransformer, self).__init__()\n",
    "\n",
    "        self.forward_expansion = forward_expansion\n",
    "        # 第一次卷积扩充通道数\n",
    "        \n",
    "        # enbedded = head * d_k head是超参数\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, embed_size, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.Transformer = Transformer(\n",
    "            adj, # GCN用的\n",
    "            embed_size, \n",
    "            num_layers, \n",
    "            heads, \n",
    "            time_num, # t-attention 中 position-encoding， 等于输入步长 time step-in == time num == 12\n",
    "            forward_expansion,\n",
    "            cheb_K, # GCN\n",
    "            dropout = 0 # 剪枝\n",
    "        )\n",
    "\n",
    "        # 缩小时间维度。  例：T_dim=12到output_T_dim=3，输入12维降到输出3维\n",
    "        self.conv2 = nn.Conv2d(T_dim, output_T_dim, 1)  \n",
    "        # 缩小通道数，降到1维。\n",
    "        self.conv3 = nn.Conv2d(embed_size, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         platform: (CHANNEL, TIMESTEP_IN, N_NODE)\n",
    "        \n",
    "        \n",
    "        # input x shape[ C, N, T] \n",
    "        # C:通道数量。  N:传感器数量。  T:时间数量\n",
    "        \n",
    "#         x = x.unsqueeze(0)\n",
    "        \n",
    "#         x = np.transpose(x,(0,2,1)).to(DEVICE)\n",
    "        input_Transformer = self.conv1(x)        \n",
    "#         input_Transformer = input_Transformer.squeeze(0)\n",
    "#         input_Transformer = input_Transformer.permute(1, 2, 0)\n",
    "        input_Transformer = input_Transformer.permute(0, 2, 3, 1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #input_Transformer shape[N, T, C]   [B, N, T, C]\n",
    "        output_Transformer = self.Transformer(input_Transformer, self.forward_expansion)  # [B, N, T, C]\n",
    "        output_Transformer = output_Transformer.permute(0, 2, 1, 3)\n",
    "        #output_Transformer shape[B, T, N, C]\n",
    "        \n",
    "#         output_Transformer = output_Transformer.unsqueeze(0)     \n",
    "        out = self.relu(self.conv2(output_Transformer))    # 等号左边 out shape: [1, output_T_dim, N, C]        \n",
    "        out = out.permute(0, 3, 2, 1)           # 等号左边 out shape: [B, C, N, output_T_dim]\n",
    "        out = self.conv3(out)                   # 等号左边 out shape: [B, 1, N, output_T_dim]   \n",
    "#         out = out.squeeze(1)\n",
    "        out = out.permute(0,1,3,2)\n",
    "#         print('out: ',out.shape)\n",
    "        return out #[B, N, output_dim]\n",
    "        # return out shape: [N, output_dim]\n",
    "\n",
    "\n",
    "def print_params(model_name, model):\n",
    "    param_count=0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            param_count += param.numel()\n",
    "    print(f'{model_name}, {param_count} trainable parameters in total.')\n",
    "    return\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(\"../BEIJINGAIR/air_data/b0_V_10.csv\", nrows = 35064, header= None)\n",
    "v = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35064, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_num = 1\n",
    "os.environ ['OMP_NUM_THREADS'] = str(cpu_num)\n",
    "os.environ ['OPENBLAS_NUM_THREADS'] = str(cpu_num)\n",
    "os.environ ['MKL_NUM_THREADS'] = str(cpu_num)\n",
    "os.environ ['VECLIB_MAXIMUM_THREADS'] = str(cpu_num)\n",
    "os.environ ['NUMEXPR_NUM_THREADS'] = str(cpu_num)\n",
    "torch.set_num_threads(cpu_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "BATCHSIZE = 32\n",
    "EPOCH = 200\n",
    "\n",
    "\n",
    "\n",
    "def getXSYS(data, mode):\n",
    "    TRAIN_NUM = int(data.shape[0] * TRAINRATIO)\n",
    "    XS, YS = [], []\n",
    "    if mode == 'TRAIN':    \n",
    "        for i in range(TRAIN_NUM - TIMESTEP_OUT - TIMESTEP_IN + 1):\n",
    "            x = data[i:i+TIMESTEP_IN, :]\n",
    "            y = data[i+TIMESTEP_IN:i+TIMESTEP_IN+TIMESTEP_OUT, :]\n",
    "            XS.append(x), YS.append(y)\n",
    "    elif mode == 'TEST':\n",
    "        for i in range(TRAIN_NUM - TIMESTEP_IN,  data.shape[0] - TIMESTEP_OUT - TIMESTEP_IN + 1):\n",
    "            x = data[i:i+TIMESTEP_IN, :]\n",
    "            y = data[i+TIMESTEP_IN:i+TIMESTEP_IN+TIMESTEP_OUT, :]\n",
    "            XS.append(x), YS.append(y)\n",
    "    XS, YS = np.array(XS), np.array(YS)\n",
    "    XS, YS = XS[:, :, :, np.newaxis], YS[:, :, :, np.newaxis]\n",
    "    XS = XS.transpose(0, 3, 2, 1)\n",
    "    YS = YS.transpose(0, 3, 1, 2)\n",
    "    print(XS.shape)\n",
    "    print(YS.shape)\n",
    "    \n",
    "    return XS, YS\n",
    "\n",
    "\n",
    "\n",
    "def getModel(name):\n",
    "#     ks, kt, bs, T, n, p = 3, 3, [[CHANNEL, 16, 64], [64, 16, 64]], TIMESTEP_IN, N_NODE, 0\n",
    "#     A = pd.read_csv(ADJPATH).values\n",
    "#     W = weight_matrix(A)\n",
    "#     L = scaled_laplacian(W)\n",
    "#     Lk = cheb_poly(L, ks)\n",
    "#     Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
    "#     model = STGCN(ks, kt, bs, T, n, Lk, p).to(device)\n",
    "#     return model\n",
    "    \n",
    "    ### Adjacency Matrix Import\n",
    "#     adj_mx = pd.read_csv('../PEMSD7M/W_228.csv')#.iloc[:,1:]\n",
    "#     adj_mx = np.array(adj_mx)\n",
    "#     A = adj_mx\n",
    "#     A = torch.Tensor(A)\n",
    "    #ADJPATH = \"../BEIJINGAIR/air_data/b_W_10.csv\"\n",
    "    A = pd.read_csv(ADJPATH,nrows = 10, header= None).values\n",
    "    \n",
    "#     print(ADJPATH)\n",
    "#     print(A)\n",
    "#     print(A.shape)\n",
    "    \n",
    "    \n",
    "    A = torch.Tensor(A)\n",
    "\n",
    "\n",
    "    ### Training Hyparameter\n",
    "    in_channels = 1 # Channels of input\n",
    "    embed_size = 64 # Dimension of hidden embedding features\n",
    "    time_num = 24 \n",
    "    num_layers = 2 # Number of ST Block\n",
    "    T_dim = 12 # Input length, should be the same as prepareData.py\n",
    "    output_T_dim = 12 # Output Expected length\n",
    "    heads = 4 # Number of Heads in MultiHeadAttention\n",
    "    cheb_K = 2 # Order for Chebyshev Polynomials (Eq 2)\n",
    "    forward_expansion = 4 # Dimension of Feed Forward Network: embed_size --> embed_size * forward_expansion --> embed_size\n",
    "    dropout = 0\n",
    "\n",
    "    ### Construct Network\n",
    "    model = STTransformer(\n",
    "        A,\n",
    "        in_channels, \n",
    "        embed_size, \n",
    "        time_num, \n",
    "        num_layers, \n",
    "        T_dim, \n",
    "        output_T_dim, \n",
    "        heads,\n",
    "        cheb_K,\n",
    "        forward_expansion,\n",
    "        dropout).to(DEVICE)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def evaluateModel(model, criterion, data_iter):\n",
    "    model.eval()\n",
    "    l_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_iter:\n",
    "            y_pred = model(x)\n",
    "            l = criterion(y_pred, y)\n",
    "            l_sum += l.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "        return l_sum / n\n",
    "\n",
    "def predictModel(model, data_iter):\n",
    "    YS_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_iter:\n",
    "            YS_pred_batch = model(x)\n",
    "            YS_pred_batch = YS_pred_batch.cpu().numpy()\n",
    "            YS_pred.append(YS_pred_batch)\n",
    "        YS_pred = np.vstack(YS_pred)\n",
    "    return YS_pred\n",
    "\n",
    "def trainModel(name, mode, XS, YS):\n",
    "    print('Model Training Started ...', time.ctime())\n",
    "    print('TIMESTEP_IN, TIMESTEP_OUT', TIMESTEP_IN, TIMESTEP_OUT)\n",
    "    model = getModel(name)\n",
    "#     summary(model, (CHANNEL,N_NODE,TIMESTEP_IN), device=device)\n",
    "    XS_torch, YS_torch = torch.Tensor(XS).to(device), torch.Tensor(YS).to(device)\n",
    "    trainval_data = torch.utils.data.TensorDataset(XS_torch, YS_torch)\n",
    "    trainval_size = len(trainval_data)\n",
    "    train_size = int(trainval_size * (1-TRAINVALSPLIT))\n",
    "    print('XS_torch.shape:  ', XS_torch.shape)\n",
    "    print('YS_torch.shape:  ', YS_torch.shape)\n",
    "    train_data = torch.utils.data.Subset(trainval_data, list(range(0, train_size)))\n",
    "    val_data = torch.utils.data.Subset(trainval_data, list(range(train_size, trainval_size)))\n",
    "    train_iter = torch.utils.data.DataLoader(train_data, BATCHSIZE, shuffle=True)\n",
    "    val_iter = torch.utils.data.DataLoader(val_data, BATCHSIZE, shuffle=True)\n",
    "    \n",
    "    min_val_loss = np.inf\n",
    "    wait = 0\n",
    "\n",
    "    print('LOSS is :',LOSS)\n",
    "    if LOSS == \"MaskMAE\":\n",
    "        criterion = Utils.masked_mae\n",
    "    if LOSS == 'MSE':\n",
    "        criterion = nn.MSELoss()\n",
    "    if LOSS == 'MAE':\n",
    "        criterion = nn.L1Loss()\n",
    "    if OPTIMIZER == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=LEARN)\n",
    "    if OPTIMIZER == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARN)\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        starttime = datetime.now()     \n",
    "        loss_sum, n = 0.0, 0\n",
    "        model.train()\n",
    "        for x, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "#             print(x.shape)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "        train_loss = loss_sum / n\n",
    "        val_loss = evaluateModel(model, criterion, val_iter)\n",
    "        if val_loss < min_val_loss:\n",
    "            wait = 0\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), PATH + '/' + name + '.pt')\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait == PATIENCE:\n",
    "                print('Early stopping at epoch: %d' % epoch)\n",
    "                break\n",
    "        endtime = datetime.now()\n",
    "        epoch_time = (endtime - starttime).seconds\n",
    "        print(\"epoch\", epoch, \"time used:\", epoch_time,\" seconds \", \"train loss:\", train_loss, \"validation loss:\", val_loss)\n",
    "        with open(PATH + '/' + name + '_log.txt', 'a') as f:\n",
    "            f.write(\"%s, %d, %s, %d, %s, %s, %.10f, %s, %.10f\\n\" % (\"epoch\", epoch, \"time used\", epoch_time, \"seconds\", \"train loss\", train_loss, \"validation loss:\", val_loss))\n",
    "            \n",
    "    torch_score = evaluateModel(model, criterion, train_iter)\n",
    "    YS_pred = predictModel(model, torch.utils.data.DataLoader(trainval_data, BATCHSIZE, shuffle=False))\n",
    "    print('YS.shape, YS_pred.shape,', YS.shape, YS_pred.shape)\n",
    "    YS, YS_pred = scaler.inverse_transform(np.squeeze(YS)), scaler.inverse_transform(np.squeeze(YS_pred))\n",
    "    print('YS.shape, YS_pred.shape,', YS.shape, YS_pred.shape)\n",
    "    MSE, RMSE, MAE, MAPE = Metrics.evaluate(YS, YS_pred)\n",
    "    with open(PATH + '/' + name + '_prediction_scores.txt', 'a') as f:\n",
    "        f.write(\"%s, %s, Torch MSE, %.10e, %.10f\\n\" % (name, mode, torch_score, torch_score))\n",
    "        f.write(\"%s, %s, MSE, RMSE, MAE, MAPE, %.10f, %.10f, %.10f, %.10f\\n\" % (name, mode, MSE, RMSE, MAE, MAPE))\n",
    "    print('*' * 40)\n",
    "    print(\"%s, %s, Torch MSE, %.10e, %.10f\" % (name, mode, torch_score, torch_score))\n",
    "    print(\"%s, %s, MSE, RMSE, MAE, MAPE, %.10f, %.10f, %.10f, %.10f\" % (name, mode, MSE, RMSE, MAE, MAPE))\n",
    "    print('Model Training Ended ...', time.ctime())\n",
    "        \n",
    "def testModel(name, mode, XS, YS):\n",
    "    if LOSS == \"MaskMAE\":\n",
    "        criterion = Utils.masked_mae\n",
    "    if LOSS == 'MSE':\n",
    "        criterion = nn.MSELoss()\n",
    "    if LOSS == 'MAE':\n",
    "        criterion = nn.L1Loss()\n",
    "    print('Model Testing Started ...', time.ctime())\n",
    "    print('TIMESTEP_IN, TIMESTEP_OUT', TIMESTEP_IN, TIMESTEP_OUT)\n",
    "    XS_torch, YS_torch = torch.Tensor(XS).to(device), torch.Tensor(YS).to(device)\n",
    "    test_data = torch.utils.data.TensorDataset(XS_torch, YS_torch)\n",
    "    test_iter = torch.utils.data.DataLoader(test_data, BATCHSIZE, shuffle=False)\n",
    "    model = getModel(name)\n",
    "    model.load_state_dict(torch.load(PATH+ '/' + name + '.pt'))\n",
    "    \n",
    "    torch_score = evaluateModel(model, criterion, test_iter)\n",
    "    YS_pred = predictModel(model, test_iter)\n",
    "    print('YS.shape, YS_pred.shape,', YS.shape, YS_pred.shape)\n",
    "    YS, YS_pred = scaler.inverse_transform(np.squeeze(YS)), scaler.inverse_transform(np.squeeze(YS_pred))\n",
    "    print('YS.shape, YS_pred.shape,', YS.shape, YS_pred.shape)\n",
    "    np.save(PATH + '/' + MODELNAME + '_prediction.npy', YS_pred)\n",
    "    np.save(PATH + '/' + MODELNAME + '_groundtruth.npy', YS)\n",
    "    MSE, RMSE, MAE, MAPE = Metrics.evaluate(YS, YS_pred)\n",
    "    print('*' * 40)\n",
    "    print(\"%s, %s, Torch MSE, %.10e, %.10f\" % (name, mode, torch_score, torch_score))\n",
    "    f = open(PATH + '/' + name + '_prediction_scores.txt', 'a')\n",
    "    f.write(\"%s, %s, Torch MSE, %.10e, %.10f\\n\" % (name, mode, torch_score, torch_score))\n",
    "    print(\"all pred steps, %s, %s, MSE, RMSE, MAE, MAPE, %.10f, %.10f, %.10f, %.10f\" % (name, mode, MSE, RMSE, MAE, MAPE))\n",
    "    f.write(\"all pred steps, %s, %s, MSE, RMSE, MAE, MAPE, %.10f, %.10f, %.10f, %.10f\\n\" % (name, mode, MSE, RMSE, MAE, MAPE))\n",
    "    for i in range(TIMESTEP_OUT):\n",
    "        MSE, RMSE, MAE, MAPE = Metrics.evaluate(YS[:, i, :], YS_pred[:, i, :])\n",
    "        print(\"%d step, %s, %s, MSE, RMSE, MAE, MAPE, %.10f, %.10f, %.10f, %.10f\" % (i+1, name, mode, MSE, RMSE, MAE, MAPE))\n",
    "        f.write(\"%d step, %s, %s, MSE, RMSE, MAE, MAPE, %.10f, %.10f, %.10f, %.10f\\n\" % (i+1, name, mode, MSE, RMSE, MAE, MAPE))\n",
    "    f.close()\n",
    "    print('Model Testing Ended ...', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (35064, 10)\n"
     ]
    }
   ],
   "source": [
    "MODELNAME = 'STTN'\n",
    "KEYWORD = 'pred_' + DATANAME + '_' + MODELNAME + '_' + datetime.now().strftime(\"%y%m%d%H%M\")\n",
    "PATH = '../save/' + KEYWORD\n",
    "torch.manual_seed(100)\n",
    "torch.cuda.manual_seed(100)\n",
    "np.random.seed(100)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "########################################################### \n",
    "GPU = '0'\n",
    "device = torch.device(\"cuda:{}\".format(GPU)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "###########################################################\n",
    "v = pd.read_csv(\"../BEIJINGAIR/air_data/b0_V_10.csv\", nrows = 35064, header= None)\n",
    "v = np.array(v)\n",
    "v = v.T\n",
    "v = torch.tensor(v, dtype=torch.float32)\n",
    "v = v.transpose(1,0)\n",
    "data = v\n",
    "#data = pd.read_hdf(FLOWPATH).values\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "print('data.shape', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_BEIJING-AIR_STTN_2201101911 training started Mon Jan 10 19:11:23 2022\n",
      "(28028, 1, 10, 12)\n",
      "(28028, 1, 12, 10)\n"
     ]
    }
   ],
   "source": [
    "print(KEYWORD, 'training started', time.ctime())\n",
    "trainXS, trainYS = getXSYS(data, 'TRAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN XS.shape YS,shape (28028, 1, 10, 12) (28028, 1, 12, 10)\n"
     ]
    }
   ],
   "source": [
    "print('TRAIN XS.shape YS,shape', trainXS.shape, trainYS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Started ... Mon Jan 10 19:13:32 2022\n",
      "TIMESTEP_IN, TIMESTEP_OUT 12 12\n",
      "XS_torch.shape:   torch.Size([28028, 1, 10, 12])\n",
      "YS_torch.shape:   torch.Size([28028, 1, 12, 10])\n",
      "LOSS is : MAE\n",
      "epoch 0 time used: 17  seconds  train loss: 0.4050197734361837 validation loss: 0.41374020203607814\n",
      "epoch 1 time used: 18  seconds  train loss: 0.38149896095888275 validation loss: 0.4050885876428047\n",
      "epoch 2 time used: 17  seconds  train loss: 0.3789183527372183 validation loss: 0.40481855158936486\n",
      "epoch 3 time used: 17  seconds  train loss: 0.37719852010298854 validation loss: 0.40515188267241875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-980421d5b8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELNAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainXS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainYS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-f13d6c9b0a95>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(name, mode, XS, YS)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m#             print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cseadmin/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-57ae2cd121dc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;31m#input_Transformer shape[N, T, C]   [B, N, T, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0moutput_Transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_Transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_expansion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, N, T, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0moutput_Transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_Transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;31m#output_Transformer shape[B, T, N, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cseadmin/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-57ae2cd121dc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, t)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;31m## scr: [N, T, C]   [B, N, T, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0menc_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0menc_src\u001b[0m \u001b[0;31m# [B, N, T, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cseadmin/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-57ae2cd121dc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# In the Encoder the query, key, value are all the same.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cseadmin/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-57ae2cd121dc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, value, key, query, t)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# Add skip connection,run through normalization and finally dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(B, N, T, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainModel(MODELNAME, 'train', trainXS, trainYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.7",
   "language": "python",
   "name": "torch1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
